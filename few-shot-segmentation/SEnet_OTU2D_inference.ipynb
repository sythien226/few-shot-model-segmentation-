{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f178ab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd2t/miniconda3/envs/UniverSeg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1+cu116\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Th√™m path ƒë·ªÉ import module\n",
    "sys.path.insert(0, '/thiends/hdd2t/few_shot_model/few-shot-segmentation')\n",
    "\n",
    "%matplotlib inline\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1536d3",
   "metadata": {},
   "source": [
    "## 1. C·∫•u h√¨nh Dataset OTU_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a34a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ================= CONFIG =================\n",
    "DATA_ROOT = \"/thiends/hdd2t/UniverSeg/OTU_2D\"  # ƒêi·ªÅu ch·ªânh path ph√π h·ª£p\n",
    "TRAIN_IMAGES = os.path.join(DATA_ROOT, \"train1/Image/\")\n",
    "TRAIN_LABELS = os.path.join(DATA_ROOT, \"train1/Label/\")\n",
    "VAL_IMAGES = os.path.join(DATA_ROOT, \"validation1/Image/\")\n",
    "VAL_LABELS = os.path.join(DATA_ROOT, \"validation1/Label/\")\n",
    "TRAIN_TXT = os.path.join(DATA_ROOT, \"train.txt\")\n",
    "VAL_TXT = os.path.join(DATA_ROOT, \"val.txt\")\n",
    "TRAIN_CLS = os.path.join(DATA_ROOT, \"train_cls.txt\")\n",
    "VAL_CLS = os.path.join(DATA_ROOT, \"val_cls.txt\")\n",
    "\n",
    "# SEnet y√™u c·∫ßu input size nh·∫•t ƒë·ªãnh (c√≥ th·ªÉ thay ƒë·ªïi)\n",
    "RESIZE_TO = (256, 256)  # SEnet th∆∞·ªùng d√πng size l·ªõn h∆°n\n",
    "NUM_CLASSES = 8\n",
    "LABEL_NAMES = [f\"Class {i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "# ==========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe17c2",
   "metadata": {},
   "source": [
    "## 2. Dataset v√† Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c0e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ki·ªÉm tra process_mask...\n",
      "   Mask path: /thiends/hdd2t/UniverSeg/OTU_2D/train1/Label/1279.PNG\n",
      "   Mask unique values: [0. 1.]\n",
      "   Mask shape: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Load class labels\n",
    "def load_cls_labels(filepath):\n",
    "    labels = {}\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                filename = parts[0].replace('.JPG', '')\n",
    "                cls = int(parts[1])\n",
    "                labels[filename] = cls\n",
    "    return labels\n",
    "\n",
    "train_cls_labels = load_cls_labels(TRAIN_CLS)\n",
    "val_cls_labels = load_cls_labels(VAL_CLS)\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def process_image(image_path, resize_to):\n",
    "    \"\"\"Load v√† preprocess ·∫£nh cho SEnet (grayscale, 1 channel)\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")  # Grayscale cho SEnet\n",
    "        img = img.resize(resize_to, Image.BILINEAR)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        return img[np.newaxis, :, :]  # [1, H, W]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image_rgb(image_path, resize_to):\n",
    "    \"\"\"Load ·∫£nh RGB ƒë·ªÉ hi·ªÉn th·ªã\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = img.resize(resize_to, Image.BILINEAR)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        return np.transpose(img, (2, 0, 1))  # [3, H, W]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def process_mask(mask_path, resize_to):\n",
    "    \"\"\"Load mask v√† BINARY h√≥a: pixel > 0 ‚Üí 1.0, pixel = 0 ‚Üí 0.0\"\"\"\n",
    "    try:\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        mask = mask.resize(resize_to, Image.NEAREST)\n",
    "        mask = np.array(mask, dtype=np.float32)\n",
    "        # Binary h√≥a mask\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        return mask\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# === VERIFY MASK LOADING ===\n",
    "print(\"üîç Ki·ªÉm tra process_mask...\")\n",
    "if os.path.exists(TRAIN_LABELS):\n",
    "    test_mask_path = os.path.join(TRAIN_LABELS, os.listdir(TRAIN_LABELS)[0])\n",
    "    test_mask = process_mask(test_mask_path, RESIZE_TO)\n",
    "    print(f\"   Mask path: {test_mask_path}\")\n",
    "    print(f\"   Mask unique values: {np.unique(test_mask)}\")\n",
    "    print(f\"   Mask shape: {test_mask.shape}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è TRAIN_LABELS path kh√¥ng t·ªìn t·∫°i: {TRAIN_LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3752e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Dataset cho SEnet ----------\n",
    "class OTU2DDatasetSEnet:\n",
    "    \"\"\"\n",
    "    Dataset cho SEnet Few-Shot Segmentation.\n",
    "    SEnet y√™u c·∫ßu:\n",
    "    - Query input: [1, H, W] grayscale\n",
    "    - Support input: [2, H, W] = concat(grayscale_image, binary_mask)\n",
    "    \"\"\"\n",
    "    def __init__(self, images_dir, labels_dir, ids_file, cls_labels, resize_to=RESIZE_TO):\n",
    "        self.samples = []\n",
    "        self.cls_labels = cls_labels\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.resize_to = resize_to\n",
    "\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Loading OTU2DDatasetSEnet from {os.path.basename(images_dir)}...\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        with open(ids_file, 'r') as f:\n",
    "            ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        for id_ in ids:\n",
    "            img_name = f\"{id_}.JPG\"\n",
    "            mask_name = f\"{id_}.PNG\"\n",
    "            img_path = os.path.join(images_dir, img_name)\n",
    "            mask_path = os.path.join(labels_dir, mask_name)\n",
    "\n",
    "            if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
    "                continue\n",
    "\n",
    "            cls = self.cls_labels.get(id_, None)\n",
    "            if cls is None:\n",
    "                continue\n",
    "\n",
    "            # Load grayscale image cho SEnet\n",
    "            img_gray = process_image(img_path, resize_to)\n",
    "            if img_gray is None:\n",
    "                continue\n",
    "\n",
    "            # Load RGB cho visualization\n",
    "            img_rgb = process_image_rgb(img_path, resize_to)\n",
    "\n",
    "            mask = process_mask(mask_path, resize_to)\n",
    "            if mask is None:\n",
    "                continue\n",
    "\n",
    "            if np.sum(mask) < 1:  # Skip n·∫øu kh√¥ng c√≥ mask\n",
    "                continue\n",
    "\n",
    "            self.samples.append({\n",
    "                'img_gray': img_gray,      # [1, H, W]\n",
    "                'img_rgb': img_rgb,        # [3, H, W] ho·∫∑c None\n",
    "                'mask': mask,              # [H, W]\n",
    "                'cls': cls,\n",
    "                'img_path': img_path\n",
    "            })\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} valid samples.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return {\n",
    "            'img_gray': torch.from_numpy(sample['img_gray']).float(),\n",
    "            'img_rgb': torch.from_numpy(sample['img_rgb']).float() if sample['img_rgb'] is not None else None,\n",
    "            'mask': torch.from_numpy(sample['mask']).float(),\n",
    "            'cls': sample['cls'],\n",
    "            'img_path': sample['img_path']\n",
    "        }\n",
    "    \n",
    "    def get_samples_by_class(self, cls_idx):\n",
    "        \"\"\"L·∫•y indices c·ªßa c√°c samples thu·ªôc class cls_idx\"\"\"\n",
    "        return [i for i, s in enumerate(self.samples) if s['cls'] == cls_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545ef470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Loading OTU2DDatasetSEnet from ...\n",
      "======================================================================\n",
      "Loaded 1000 valid samples.\n",
      "======================================================================\n",
      "Loading OTU2DDatasetSEnet from ...\n",
      "======================================================================\n",
      "Loaded 469 valid samples.\n",
      "\n",
      "T·ªïng s·ªë ·∫£nh trong support pool: 1000\n",
      "T·ªïng s·ªë ·∫£nh trong test set: 469\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "support_pool = OTU2DDatasetSEnet(TRAIN_IMAGES, TRAIN_LABELS, TRAIN_TXT, train_cls_labels)\n",
    "test_set = OTU2DDatasetSEnet(VAL_IMAGES, VAL_LABELS, VAL_TXT, val_cls_labels)\n",
    "\n",
    "print(f\"\\nT·ªïng s·ªë ·∫£nh trong support pool: {len(support_pool)}\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh trong test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28c3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Ph√¢n b·ªë nh√£n trong SUPPORT POOL:\n",
      "Class      Name            Count      Percentage\n",
      "--------------------------------------------------\n",
      "0          Class 0         226        22.6%\n",
      "1          Class 1         153        15.3%\n",
      "2          Class 2         228        22.8%\n",
      "3          Class 3         57         5.7%\n",
      "4          Class 4         47         4.7%\n",
      "5          Class 5         180        18.0%\n",
      "6          Class 6         71         7.1%\n",
      "7          Class 7         38         3.8%\n",
      "\n",
      "[INFO] Ph√¢n b·ªë nh√£n trong TEST SET:\n",
      "Class      Name            Count      Percentage\n",
      "--------------------------------------------------\n",
      "0          Class 0         110        23.5%\n",
      "1          Class 1         66         14.1%\n",
      "2          Class 2         108        23.0%\n",
      "3          Class 3         31         6.6%\n",
      "4          Class 4         19         4.1%\n",
      "5          Class 5         87         18.6%\n",
      "6          Class 6         33         7.0%\n",
      "7          Class 7         15         3.2%\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch ph√¢n b·ªë nh√£n\n",
    "label_indices_support = defaultdict(list)\n",
    "label_indices_test = defaultdict(list)\n",
    "\n",
    "for idx in range(len(support_pool)):\n",
    "    sample = support_pool.samples[idx]\n",
    "    label_indices_support[sample['cls']].append(idx)\n",
    "\n",
    "for idx in range(len(test_set)):\n",
    "    sample = test_set.samples[idx]\n",
    "    label_indices_test[sample['cls']].append(idx)\n",
    "\n",
    "print(\"\\n[INFO] Ph√¢n b·ªë nh√£n trong SUPPORT POOL:\")\n",
    "print(f\"{'Class':<10} {'Name':<15} {'Count':<10} {'Percentage':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for cls_idx in range(NUM_CLASSES):\n",
    "    count = len(label_indices_support[cls_idx])\n",
    "    pct = 100 * count / len(support_pool) if len(support_pool) > 0 else 0\n",
    "    print(f\"{cls_idx:<10} {LABEL_NAMES[cls_idx]:<15} {count:<10} {pct:.1f}%\")\n",
    "\n",
    "print(\"\\n[INFO] Ph√¢n b·ªë nh√£n trong TEST SET:\")\n",
    "print(f\"{'Class':<10} {'Name':<15} {'Count':<10} {'Percentage':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for cls_idx in range(NUM_CLASSES):\n",
    "    count = len(label_indices_test[cls_idx])\n",
    "    pct = 100 * count / len(test_set) if len(test_set) > 0 else 0\n",
    "    print(f\"{cls_idx:<10} {LABEL_NAMES[cls_idx]:<15} {count:<10} {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709a601",
   "metadata": {},
   "source": [
    "## 3. Load Model SEnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba6021f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (modules.py, line 526)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/mnt/hdd2t/miniconda3/envs/UniverSeg/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[8], line 2\u001b[0m\n    from few_shot_segmentor import FewShotSegmentorDoubleSDnet\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/thiends/hdd2t/few_shot_model/few-shot-segmentation/few_shot_segmentor.py:6\u001b[0;36m\n\u001b[0;31m    from nn_common_modules import modules as sm\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/mnt/hdd2t/miniconda3/envs/UniverSeg/lib/python3.10/site-packages/nn_common_modules/modules.py:526\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:abdominal_segmentation_2] - 1) / 2)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "# Import SEnet model\n",
    "from few_shot_segmentor import FewShotSegmentorDoubleSDnet\n",
    "\n",
    "# ============ CH·ªåN MODEL PATH ============\n",
    "# Thay ƒë·ªïi path ƒë·∫øn model ƒë√£ train\n",
    "MODEL_PATH = \"saved_models/sne_position_all_type_spatial_fold2.pth.tar\"  # V√≠ d·ª•\n",
    "\n",
    "# Ho·∫∑c t·∫°o model m·ªõi (ch∆∞a train)\n",
    "CREATE_NEW_MODEL = True  # Set False n·∫øu mu·ªën load pretrained\n",
    "# =========================================\n",
    "\n",
    "# Model parameters (theo settings.ini)\n",
    "net_params = {\n",
    "    'num_class': 2,\n",
    "    'num_channels': 1,\n",
    "    'num_filters': 64,\n",
    "    'kernel_h': 5,\n",
    "    'kernel_w': 5,\n",
    "    'kernel_c': 1,\n",
    "    'stride_conv': 1,\n",
    "    'pool': 2,\n",
    "    'stride_pool': 2,\n",
    "    'se_block': 'NONE',\n",
    "    'drop_out': 0\n",
    "}\n",
    "\n",
    "if CREATE_NEW_MODEL:\n",
    "    print(\"üî® T·∫°o model SEnet m·ªõi (ch∆∞a train)...\")\n",
    "    model = FewShotSegmentorDoubleSDnet(net_params)\n",
    "    print(\"‚úÖ Model created successfully!\")\n",
    "else:\n",
    "    print(f\"üìÇ Loading pretrained model t·ª´: {MODEL_PATH}\")\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        model = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "        print(\"‚úÖ Model loaded successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Model file kh√¥ng t·ªìn t·∫°i: {MODEL_PATH}\")\n",
    "        print(\"   ‚Üí T·∫°o model m·ªõi thay th·∫ø...\")\n",
    "        model = FewShotSegmentorDoubleSDnet(net_params)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# In th√¥ng tin model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nüìä Model Info:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec766fd5",
   "metadata": {},
   "source": [
    "## 4. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a522fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_senet_inputs(query_sample, support_samples):\n",
    "    \"\"\"\n",
    "    Chu·∫©n b·ªã input cho SEnet:\n",
    "    - query_input: [B, 1, H, W] - ·∫£nh grayscale c·ªßa query\n",
    "    - condition_input: [B, 2, H, W] - concat(support_image, support_mask)\n",
    "    \n",
    "    Args:\n",
    "        query_sample: dict v·ªõi 'img_gray' [1, H, W]\n",
    "        support_samples: list of dicts v·ªõi 'img_gray' [1, H, W] v√† 'mask' [H, W]\n",
    "    \n",
    "    Returns:\n",
    "        query_input: [1, 1, H, W]\n",
    "        condition_input: [N, 2, H, W] n·∫øu N > 1, ho·∫∑c averaged condition\n",
    "    \"\"\"\n",
    "    # Query input\n",
    "    query_input = query_sample['img_gray'].unsqueeze(0)  # [1, 1, H, W]\n",
    "    \n",
    "    # Support/Condition inputs\n",
    "    condition_inputs = []\n",
    "    for sup in support_samples:\n",
    "        sup_img = sup['img_gray']  # [1, H, W]\n",
    "        sup_mask = sup['mask'].unsqueeze(0)  # [1, H, W]\n",
    "        condition = torch.cat([sup_img, sup_mask], dim=0)  # [2, H, W]\n",
    "        condition_inputs.append(condition)\n",
    "    \n",
    "    # Stack v√† average n·∫øu c√≥ nhi·ªÅu support\n",
    "    condition_stack = torch.stack(condition_inputs, dim=0)  # [N, 2, H, W]\n",
    "    \n",
    "    # SEnet m·∫∑c ƒë·ªãnh nh·∫≠n 1 condition input, n√™n average ho·∫∑c ch·ªçn 1\n",
    "    # ·ªû ƒë√¢y ta d√πng average c·ªßa c√°c support masks\n",
    "    avg_condition = condition_stack.mean(dim=0, keepdim=True)  # [1, 2, H, W]\n",
    "    \n",
    "    return query_input, avg_condition\n",
    "\n",
    "\n",
    "def senet_inference(model, query_sample, support_samples, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Th·ª±c hi·ªán inference v·ªõi SEnet.\n",
    "    \n",
    "    Returns:\n",
    "        pred: prediction probabilities [H, W]\n",
    "    \"\"\"\n",
    "    query_input, condition_input = prepare_senet_inputs(query_sample, support_samples)\n",
    "    \n",
    "    query_input = query_input.to(device)\n",
    "    condition_input = condition_input.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # SEnet: forward(condition_input, query_input)\n",
    "        # Output: softmax probabilities [B, 2, H, W]\n",
    "        output = model(condition_input, query_input)\n",
    "        \n",
    "        # L·∫•y probability c·ªßa class 1 (foreground)\n",
    "        pred = output[0, 1]  # [H, W]\n",
    "    \n",
    "    return pred.cpu()\n",
    "\n",
    "\n",
    "def compute_metrics(pred, gt, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"T√≠nh Dice, IoU, Precision, Recall\"\"\"\n",
    "    pred_bin = (pred > threshold).float()\n",
    "    gt = gt.float()\n",
    "    \n",
    "    TP = (pred_bin * gt).sum()\n",
    "    FP = (pred_bin * (1 - gt)).sum()\n",
    "    FN = ((1 - pred_bin) * gt).sum()\n",
    "    \n",
    "    dice = (2 * TP + smooth) / (2 * TP + FP + FN + smooth)\n",
    "    iou = (TP + smooth) / (TP + FP + FN + smooth)\n",
    "    precision = (TP + smooth) / (TP + FP + smooth)\n",
    "    recall = (TP + smooth) / (TP + FN + smooth)\n",
    "    \n",
    "    return {\n",
    "        'dice': dice.item(),\n",
    "        'iou': iou.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adf50a",
   "metadata": {},
   "source": [
    "## 5. Test v·ªõi 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5be7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference v·ªõi 1 sample\n",
    "print(\"üß™ Test inference v·ªõi 1 sample...\\n\")\n",
    "\n",
    "# Ch·ªçn query t·ª´ test set\n",
    "query_idx = 0\n",
    "query_sample = test_set[query_idx]\n",
    "target_class = query_sample['cls']\n",
    "\n",
    "print(f\"Query image: {query_sample['img_path']}\")\n",
    "print(f\"Target class: {target_class} ({LABEL_NAMES[target_class]})\")\n",
    "\n",
    "# L·∫•y support samples t·ª´ c√πng class\n",
    "support_indices = label_indices_support[target_class][:5]  # L·∫•y 5 support\n",
    "support_samples = [support_pool[i] for i in support_indices]\n",
    "\n",
    "print(f\"Number of support samples: {len(support_samples)}\")\n",
    "\n",
    "# Inference\n",
    "pred = senet_inference(model, query_sample, support_samples)\n",
    "\n",
    "# Compute metrics\n",
    "gt = query_sample['mask']\n",
    "metrics = compute_metrics(pred, gt)\n",
    "\n",
    "print(f\"\\nüìä Metrics:\")\n",
    "print(f\"   Dice:      {metrics['dice']:.4f}\")\n",
    "print(f\"   IoU:       {metrics['iou']:.4f}\")\n",
    "print(f\"   Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:    {metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize k·∫øt qu·∫£\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "# Query image (grayscale)\n",
    "axes[0].imshow(query_sample['img_gray'][0], cmap='gray')\n",
    "axes[0].set_title(f\"Query Image\\nClass: {LABEL_NAMES[target_class]}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Ground Truth\n",
    "axes[1].imshow(gt.numpy(), cmap='gray')\n",
    "axes[1].set_title(f\"Ground Truth\\nPixels: {gt.sum():.0f}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Prediction (heatmap)\n",
    "axes[2].imshow(pred.numpy(), cmap='hot', vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"Prediction\\nmax: {pred.max():.3f}\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Binary prediction\n",
    "pred_bin = (pred > 0.5).float()\n",
    "axes[3].imshow(pred_bin.numpy(), cmap='gray')\n",
    "axes[3].set_title(f\"Binary Pred (>0.5)\\nPixels: {pred_bin.sum():.0f}\")\n",
    "axes[3].axis('off')\n",
    "\n",
    "# Overlay\n",
    "if query_sample['img_rgb'] is not None:\n",
    "    overlay = query_sample['img_rgb'].permute(1, 2, 0).numpy()\n",
    "else:\n",
    "    overlay = np.stack([query_sample['img_gray'][0]]*3, axis=-1)\n",
    "axes[4].imshow(overlay)\n",
    "axes[4].contour(gt.numpy(), colors='red', linewidths=2, levels=[0.5])\n",
    "axes[4].contour(pred_bin.numpy(), colors='lime', linewidths=2, levels=[0.5])\n",
    "axes[4].set_title(f\"Overlay\\nDice: {metrics['dice']:.3f}\\nRed=GT, Green=Pred\")\n",
    "axes[4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676c3fc",
   "metadata": {},
   "source": [
    "## 6. ƒê√°nh gi√° theo s·ªë l∆∞·ª£ng Support (N-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11451be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== ƒê√ÅNH GI√Å THEO N ==================\n",
    "N_LIST = [1, 2, 4, 8, 16, 32]\n",
    "NUM_TEST_SAMPLES = min(100, len(test_set))  # Gi·ªõi h·∫°n ƒë·ªÉ test nhanh\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ƒê√ÅNH GI√Å METRICS TRUNG B√åNH THEO S·ªê L∆Ø·ª¢NG SUPPORT (N)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_by_N = {N: {'dice': [], 'iou': [], 'precision': [], 'recall': []} for N in N_LIST}\n",
    "\n",
    "print(f\"\\nƒêang ƒë√°nh gi√° tr√™n {NUM_TEST_SAMPLES} ·∫£nh test...\")\n",
    "\n",
    "for idx in tqdm(range(NUM_TEST_SAMPLES), desc=\"Evaluating\"):\n",
    "    query_sample = test_set[idx]\n",
    "    target_class = query_sample['cls']\n",
    "    gt = query_sample['mask']\n",
    "    \n",
    "    # Skip n·∫øu mask qu√° nh·ªè\n",
    "    if gt.sum() < 10:\n",
    "        continue\n",
    "    \n",
    "    # L·∫•y support pool c·ªßa class n√†y\n",
    "    class_support_indices = label_indices_support[target_class]\n",
    "    \n",
    "    if len(class_support_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    for N in N_LIST:\n",
    "        # L·∫•y N support samples (random)\n",
    "        K = min(N, len(class_support_indices))\n",
    "        selected_indices = np.random.choice(class_support_indices, size=K, replace=False)\n",
    "        support_samples = [support_pool[i] for i in selected_indices]\n",
    "        \n",
    "        # Inference\n",
    "        pred = senet_inference(model, query_sample, support_samples)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = compute_metrics(pred, gt, threshold=THRESHOLD)\n",
    "        \n",
    "        for key in metrics:\n",
    "            results_by_N[N][key].append(metrics[key])\n",
    "\n",
    "# T√≠nh trung b√¨nh\n",
    "avg_results = []\n",
    "for N in N_LIST:\n",
    "    row = {'N': N}\n",
    "    for metric in ['dice', 'iou', 'precision', 'recall']:\n",
    "        values = results_by_N[N][metric]\n",
    "        row[metric] = np.mean(values) if values else 0\n",
    "        row[f'{metric}_std'] = np.std(values) if values else 0\n",
    "    avg_results.append(row)\n",
    "\n",
    "df_avg = pd.DataFrame(avg_results)\n",
    "\n",
    "# Hi·ªÉn th·ªã b·∫£ng\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"K·∫æT QU·∫¢ TRUNG B√åNH THEO N:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'N':>4} | {'Dice':>14} | {'IoU':>14} | {'Precision':>14} | {'Recall':>14}\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in df_avg.iterrows():\n",
    "    print(f\"{int(row['N']):>4} | {row['dice']:.4f}¬±{row['dice_std']:.3f} | \"\n",
    "          f\"{row['iou']:.4f}¬±{row['iou_std']:.3f} | \"\n",
    "          f\"{row['precision']:.4f}¬±{row['precision_std']:.3f} | \"\n",
    "          f\"{row['recall']:.4f}¬±{row['recall_std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f01229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "metrics_names = ['dice', 'iou', 'precision', 'recall']\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']\n",
    "\n",
    "for ax, metric, color in zip(axes, metrics_names, colors):\n",
    "    means = df_avg[metric].values\n",
    "    stds = df_avg[f'{metric}_std'].values\n",
    "    \n",
    "    ax.plot(N_LIST, means, 'o-', color=color, linewidth=2, markersize=8)\n",
    "    ax.fill_between(N_LIST, means - stds, means + stds, alpha=0.2, color=color)\n",
    "    ax.set_xlabel('Number of Support Images (N)', fontsize=12)\n",
    "    ax.set_ylabel(metric.capitalize(), fontsize=12)\n",
    "    ax.set_title(f'SEnet - {metric.capitalize()} vs N', fontsize=14, fontweight='bold')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xticks(N_LIST)\n",
    "    ax.set_xticklabels(N_LIST)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('SEnet Few-Shot Segmentation - Performance by Number of Supports', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('SEnet_metrics_by_N.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# L∆∞u CSV\n",
    "df_avg.to_csv('SEnet_metrics_by_N.csv', index=False)\n",
    "print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: SEnet_metrics_by_N.csv v√† SEnet_metrics_by_N.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84e72b",
   "metadata": {},
   "source": [
    "## 7. ƒê√°nh gi√° t·ª´ng Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe045867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== ƒê√ÅNH GI√Å T·ª™NG CLASS ==================\n",
    "N_SELECTED = 8  # S·ªë support images\n",
    "NUM_SAMPLES_PER_CLASS = 30  # S·ªë ·∫£nh t·ªëi ƒëa ƒë·ªÉ ƒë√°nh gi√° m·ªói class\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"ƒê√ÅNH GI√Å METRICS CHO T·ª™NG CLASS T·∫†I N = {N_SELECTED}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class_metrics = {c: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'count': 0} \n",
    "                 for c in range(NUM_CLASSES)}\n",
    "\n",
    "for idx in tqdm(range(len(test_set)), desc=\"Evaluating per class\"):\n",
    "    query_sample = test_set[idx]\n",
    "    cls_idx = query_sample['cls']\n",
    "    gt = query_sample['mask']\n",
    "    \n",
    "    # Gi·ªõi h·∫°n s·ªë samples m·ªói class\n",
    "    if class_metrics[cls_idx]['count'] >= NUM_SAMPLES_PER_CLASS:\n",
    "        continue\n",
    "    \n",
    "    if gt.sum() < 10:\n",
    "        continue\n",
    "    \n",
    "    class_support_indices = label_indices_support[cls_idx]\n",
    "    if len(class_support_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    K = min(N_SELECTED, len(class_support_indices))\n",
    "    selected_indices = np.random.choice(class_support_indices, size=K, replace=False)\n",
    "    support_samples = [support_pool[i] for i in selected_indices]\n",
    "    \n",
    "    pred = senet_inference(model, query_sample, support_samples)\n",
    "    metrics = compute_metrics(pred, gt, threshold=THRESHOLD)\n",
    "    \n",
    "    for key in metrics:\n",
    "        class_metrics[cls_idx][key].append(metrics[key])\n",
    "    class_metrics[cls_idx]['count'] += 1\n",
    "\n",
    "# T·∫°o DataFrame k·∫øt qu·∫£\n",
    "results_per_class = []\n",
    "for cls_idx in range(NUM_CLASSES):\n",
    "    if class_metrics[cls_idx]['count'] == 0:\n",
    "        continue\n",
    "    \n",
    "    row = {\n",
    "        'Class': cls_idx,\n",
    "        'Name': LABEL_NAMES[cls_idx],\n",
    "        'Samples': class_metrics[cls_idx]['count'],\n",
    "        'Dice': np.mean(class_metrics[cls_idx]['dice']),\n",
    "        'Dice_std': np.std(class_metrics[cls_idx]['dice']),\n",
    "        'IoU': np.mean(class_metrics[cls_idx]['iou']),\n",
    "        'Precision': np.mean(class_metrics[cls_idx]['precision']),\n",
    "        'Recall': np.mean(class_metrics[cls_idx]['recall']),\n",
    "    }\n",
    "    results_per_class.append(row)\n",
    "\n",
    "df_class = pd.DataFrame(results_per_class)\n",
    "\n",
    "# Hi·ªÉn th·ªã\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"K·∫æT QU·∫¢ METRICS CHO T·ª™NG CLASS (N = {N_SELECTED}):\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\n{'Class':>6} | {'Name':>12} | {'Samples':>8} | {'Dice':>10} | {'IoU':>10} | {'Precision':>10} | {'Recall':>10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for _, row in df_class.iterrows():\n",
    "    print(f\"{int(row['Class']):>6} | {row['Name']:>12} | {int(row['Samples']):>8} | \"\n",
    "          f\"{row['Dice']:.4f} | {row['IoU']:.4f} | {row['Precision']:.4f} | {row['Recall']:.4f}\")\n",
    "\n",
    "# T·ªïng k·∫øt\n",
    "print(\"-\" * 90)\n",
    "avg_dice = df_class['Dice'].mean()\n",
    "avg_iou = df_class['IoU'].mean()\n",
    "print(f\"{'AVG':>6} | {'':>12} | {'':>8} | {avg_dice:.4f} | {avg_iou:.4f} | \"\n",
    "      f\"{df_class['Precision'].mean():.4f} | {df_class['Recall'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bar chart cho t·ª´ng class\n",
    "if len(df_class) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    metrics_to_plot = ['Dice', 'IoU', 'Precision', 'Recall']\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']\n",
    "\n",
    "    for ax, metric, color in zip(axes.flatten(), metrics_to_plot, colors):\n",
    "        x = np.arange(len(df_class))\n",
    "        means = df_class[metric].values\n",
    "        \n",
    "        bars = ax.bar(x, means, color=color, alpha=0.7, edgecolor='black')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f\"C{int(c)}\" for c in df_class['Class']], fontsize=10)\n",
    "        ax.set_xlabel('Class', fontsize=12)\n",
    "        ax.set_ylabel(metric, fontsize=12)\n",
    "        ax.set_title(f'SEnet - {metric} per Class (N={N_SELECTED})', fontsize=14, fontweight='bold')\n",
    "        ax.axhline(y=df_class[metric].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Avg: {df_class[metric].mean():.3f}')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Th√™m gi√° tr·ªã l√™n bars\n",
    "        for bar, val in zip(bars, means):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                    f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.suptitle(f'SEnet Metrics per Class (N = {N_SELECTED})', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'SEnet_metrics_per_class_N{N_SELECTED}.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # L∆∞u CSV\n",
    "    df_class.to_csv(f'SEnet_metrics_per_class_N{N_SELECTED}.csv', index=False)\n",
    "    print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: SEnet_metrics_per_class_N{N_SELECTED}.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df073d",
   "metadata": {},
   "source": [
    "## 8. Visualize k·∫øt qu·∫£ cho t·ª´ng Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 1 ·∫£nh m·ªói class v·ªõi N support kh√°c nhau\n",
    "N_VIS = [1, 4, 16]  # S·ªë N ƒë·ªÉ so s√°nh\n",
    "active_classes = [c for c in range(NUM_CLASSES) if len(label_indices_test[c]) > 0]\n",
    "\n",
    "if len(active_classes) > 0:\n",
    "    fig, axes = plt.subplots(len(N_VIS) + 2, len(active_classes), \n",
    "                              figsize=(4*len(active_classes), 4*(len(N_VIS)+2)))\n",
    "    \n",
    "    if len(active_classes) == 1:\n",
    "        axes = axes[:, np.newaxis]\n",
    "    \n",
    "    for col, cls_idx in enumerate(active_classes):\n",
    "        # L·∫•y 1 ·∫£nh test c·ªßa class n√†y\n",
    "        test_idx = label_indices_test[cls_idx][0]\n",
    "        query_sample = test_set[test_idx]\n",
    "        gt = query_sample['mask']\n",
    "        \n",
    "        # Row 0: Query image\n",
    "        if query_sample['img_rgb'] is not None:\n",
    "            axes[0, col].imshow(query_sample['img_rgb'].permute(1, 2, 0).numpy())\n",
    "        else:\n",
    "            axes[0, col].imshow(query_sample['img_gray'][0], cmap='gray')\n",
    "        axes[0, col].set_title(f\"{LABEL_NAMES[cls_idx]}\\nQuery Image\", fontsize=10)\n",
    "        axes[0, col].axis('off')\n",
    "        \n",
    "        # Row 1: Ground Truth\n",
    "        axes[1, col].imshow(gt.numpy(), cmap='gray')\n",
    "        axes[1, col].set_title(f\"Ground Truth\\nPixels: {gt.sum():.0f}\", fontsize=10)\n",
    "        axes[1, col].axis('off')\n",
    "        \n",
    "        # Rows 2+: Predictions v·ªõi N kh√°c nhau\n",
    "        class_support_indices = label_indices_support[cls_idx]\n",
    "        \n",
    "        for row, N in enumerate(N_VIS):\n",
    "            if len(class_support_indices) > 0:\n",
    "                K = min(N, len(class_support_indices))\n",
    "                selected_indices = class_support_indices[:K]\n",
    "                support_samples = [support_pool[i] for i in selected_indices]\n",
    "                \n",
    "                pred = senet_inference(model, query_sample, support_samples)\n",
    "                metrics = compute_metrics(pred, gt)\n",
    "                \n",
    "                axes[row+2, col].imshow(pred.numpy(), cmap='hot', vmin=0, vmax=1)\n",
    "                axes[row+2, col].contour(gt.numpy(), colors='lime', linewidths=1, levels=[0.5])\n",
    "                axes[row+2, col].set_title(f\"N={N}, Dice={metrics['dice']:.3f}\", fontsize=10)\n",
    "            else:\n",
    "                axes[row+2, col].text(0.5, 0.5, 'No support', ha='center', va='center', fontsize=12)\n",
    "            axes[row+2, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('SEnet Few-Shot Segmentation - Visualization per Class', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('SEnet_visualization_per_class.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng c√≥ class n√†o c√≥ d·ªØ li·ªáu test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11609a",
   "metadata": {},
   "source": [
    "## 9. T·ªïng k·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930365a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä T·ªîNG K·∫æT SEnet Few-Shot Segmentation tr√™n OTU_2D\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìÅ Dataset:\")\n",
    "print(f\"   ‚îú‚îÄ Support pool: {len(support_pool)} ·∫£nh\")\n",
    "print(f\"   ‚îî‚îÄ Test set: {len(test_set)} ·∫£nh\")\n",
    "\n",
    "print(f\"\\nüîß Model:\")\n",
    "print(f\"   ‚îú‚îÄ Type: FewShotSegmentorDoubleSDnet (SEnet)\")\n",
    "print(f\"   ‚îú‚îÄ Parameters: {total_params:,}\")\n",
    "print(f\"   ‚îî‚îÄ Input size: {RESIZE_TO}\")\n",
    "\n",
    "if len(df_avg) > 0:\n",
    "    best_row = df_avg.loc[df_avg['dice'].idxmax()]\n",
    "    print(f\"\\nüìà Best Performance:\")\n",
    "    print(f\"   ‚îú‚îÄ Best N: {int(best_row['N'])}\")\n",
    "    print(f\"   ‚îú‚îÄ Dice: {best_row['dice']:.4f}\")\n",
    "    print(f\"   ‚îú‚îÄ IoU: {best_row['iou']:.4f}\")\n",
    "    print(f\"   ‚îú‚îÄ Precision: {best_row['precision']:.4f}\")\n",
    "    print(f\"   ‚îî‚îÄ Recall: {best_row['recall']:.4f}\")\n",
    "\n",
    "if len(df_class) > 0:\n",
    "    best_class = df_class.loc[df_class['Dice'].idxmax()]\n",
    "    worst_class = df_class.loc[df_class['Dice'].idxmin()]\n",
    "    print(f\"\\nüèÜ Best class: {best_class['Name']} (Dice={best_class['Dice']:.4f})\")\n",
    "    print(f\"‚ö†Ô∏è  Worst class: {worst_class['Name']} (Dice={worst_class['Dice']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
